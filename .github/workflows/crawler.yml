name: Interstellar Relay Crawler

on:
  # 'Actions' íƒ­ì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•˜ê²Œ ì„¤ì •
  workflow_dispatch:
    inputs:
      # í¬ë¡¤ë§í•  URL ëª©ë¡ì„ ì§ì ‘ ì…ë ¥ë°›ìŒ
      urls:
        description: 'Coupang Product URLs (comma-separated)'
        required: true
        
  # ë§¤ì¼ ì•„ì¹¨ 9ì‹œì— ìë™ìœ¼ë¡œ ì‹¤í–‰ (UTC 0ì‹œ)
  schedule:
    - cron: '0 0 * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: ì €ì¥ì†Œ ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
        uses: actions/checkout@v4

      - name: Python 3.10 ì„¤ì •
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: ì˜ì¡´ì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
        run: |
          python -m pip install --upgrade pip
          pip install playwright pandas

      - name: Playwright ë¸Œë¼ìš°ì € ì„¤ì¹˜
        run: playwright install --with-deps

      - name: íŒŒì´ì¬ ìŠ¤í¬ë ˆì´í¼ ì‹¤í–‰
        # ìˆ˜ë™ ì‹¤í–‰ ì‹œ ì…ë ¥ë°›ì€ URLì„, ìë™ ì‹¤í–‰ ì‹œ íŒŒì¼ì—ì„œ URLì„ ì½ë„ë¡ ì „ë‹¬
        run: python interstellar_scraper.py "${{ github.event.inputs.urls || 'url_list.txt' }}"

      - name: ê²°ê³¼ ì»¤ë°‹ ë° í‘¸ì‹œ
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add coupang_data.csv
          # íŒŒì¼ ë³€ê²½ì´ ìˆì„ ë•Œë§Œ ì»¤ë°‹
          if ! git diff --staged --quiet; then
            git commit -m "ğŸ“Š [Auto] Update Coupang product data"
            git push
          else
            echo "No changes to commit."
          fi