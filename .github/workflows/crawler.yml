name: Interstellar Relay Crawler

# "on" 부분을 이렇게 수정합니다.
on:
  # 'Actions' 탭에서 수동으로 실행할 수 있도록 설정
  workflow_dispatch:
    inputs:
      # 크롤링할 URL 목록을 직접 입력받음 (선택 사항)
      urls:
        description: 'Coupang Product URLs (comma-separated)'
        required: false

# 👇 이 부분을 추가해 주세요.
permissions:
  contents: write

  
jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: 저장소 코드 가져오기
        uses: actions/checkout@v4

      - name: Python 3.10 설정
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: 의존성 라이브러리 설치
        run: |
          python -m pip install --upgrade pip
          pip install playwright pandas

      - name: Playwright 브라우저 설치
        run: playwright install --with-deps

      - name: 파이썬 스크레이퍼 실행
        # 수동 실행 시 입력받은 URL을, 자동 실행 시 파일에서 URL을 읽도록 전달
        run: python interstellar_scraper.py "${{ github.event.inputs.urls || 'url_list.txt' }}"

      - name: 결과 커밋 및 푸시
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add coupang_data.csv
          # 파일 변경이 있을 때만 커밋
          if ! git diff --staged --quiet; then
            git commit -m "📊 [Auto] Update Coupang product data"
            git push
          else
            echo "No changes to commit."
          fi